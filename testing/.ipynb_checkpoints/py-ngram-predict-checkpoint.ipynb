{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json,os,sys,logging,pprint,re,string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nGramDict=json.load(open('/home/yewenhe0904/Developing/ds-capstone-project/ignoredFiles/Sample-Dict/twitter-nGramDict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nGramDict['_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input='my name is donald '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanInputPredict(test_input):\n",
    "    cleanedInput=[]\n",
    "    test_tokens=test_input.strip().lower().split()\n",
    "    test_input=re.sub('\\n+',\" \",test_input)\n",
    "    for item in test_tokens:\n",
    "        item = item.strip(string.punctuation)\n",
    "        item = re.sub(r\"^.*\\d+.*$\",\"<Quantity>\",item)\n",
    "        cleanedInput.append(item)\n",
    "    return cleanedInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictCore(input_tokens,output_list,out_len=5):\n",
    "    print (input_tokens)\n",
    "    if len(input_tokens)<1:\n",
    "        output_list+=(nGramDict['_r'])\n",
    "    else:\n",
    "        # probe if in ngram record\n",
    "        nGram_flag=True\n",
    "        i=0\n",
    "        p_Dict=nGramDict['_n']\n",
    "        while nGram_flag:\n",
    "            print(i)\n",
    "            if i==len(input_tokens):\n",
    "                break\n",
    "            if (input_tokens[i] in p_Dict):\n",
    "                r_wids=p_Dict[input_tokens[i]]['_r']\n",
    "                if ('_n' in p_Dict[input_tokens[i]]):\n",
    "                    p_Dict=p_Dict[input_tokens[i]]['_n']\n",
    "                    i+=1\n",
    "                else:\n",
    "                    if i<len(input_tokens)-1:\n",
    "                        nGram_flag=False\n",
    "                    break\n",
    "            else:\n",
    "                nGram_flag=False\n",
    "                break\n",
    "        # if true\n",
    "        if nGram_flag:\n",
    "            output_list+=r_wids\n",
    "            if len(output_list)<out_len:\n",
    "                del input_tokens[0]\n",
    "                predictCore(input_tokens,output_list,out_len=out_len)\n",
    "        # else false\n",
    "        else:\n",
    "            del input_tokens[0]\n",
    "            predictCore(input_tokens,output_list,out_len=out_len)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictNgram(test_input,out_len):\n",
    "    #clean input string\n",
    "    input_tokens=cleanInputPredict(test_input)\n",
    "    if len(input_tokens)>nGramDict['_model']:\n",
    "        input_tokens=input_tokens[-nGramDict['_model']:]\n",
    "    output_list=[]\n",
    "    output_wlist=[]\n",
    "    output=[]\n",
    "    input_idtokens=[]\n",
    "    for w in input_tokens:\n",
    "        w.strip()\n",
    "        if w in nGramDict['_word2id']['_word']:\n",
    "            input_idtokens.append(nGramDict['_word2id']['_word'][w])\n",
    "        else:\n",
    "            input_idtokens.append('NA')\n",
    "    predictCore(input_idtokens,output_list,out_len)\n",
    "    for wid in output_list:\n",
    "        output_wlist.append(nGramDict['_id2word']['_id'][wid])\n",
    "    eosflag=True\n",
    "    for word in output_wlist:\n",
    "        if word=='<EOS>':\n",
    "            if eosflag:\n",
    "                output.append(',')\n",
    "                output.append('.')\n",
    "            eosflag=False\n",
    "        elif word==\"<Quantity>\":\n",
    "            pass\n",
    "        else:\n",
    "            output.append(word)\n",
    "        #dedupe\n",
    "        output_dp=[output[0]]\n",
    "        if len(output)>1:\n",
    "            for i in range(1,len(output)):\n",
    "                if output[i] not in output[:i]:\n",
    "                    output_dp.append(output[i])\n",
    "        if len(output_dp)>out_len:\n",
    "            output_dp=output_dp[0:out_len]\n",
    "    return output_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W1797', 'W24', 'W5751']\n",
      "0\n",
      "1\n",
      "2\n",
      "['W24', 'W5751']\n",
      "0\n",
      "1\n",
      "2\n",
      "['W5751']\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"trump's\", 'trump', ',', '.', 'duck']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictNgram(test_input,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
