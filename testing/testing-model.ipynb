{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json,os,sys,logging,pprint,re,string,courseraLib,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestSet: |█████████████████████████████-| 99.9% Complete\r"
     ]
    }
   ],
   "source": [
    "sample_rate=10 #1/1000\n",
    "path='/home/yewenhe0904/Developing/ds-capstone-project/testing-data/mixed-testing.txt'\n",
    "testing_set=open(path)\n",
    "\n",
    "\n",
    "# Initial call to print 0% progress\n",
    "i = 0\n",
    "l = len(list(open(path)))\n",
    "l\n",
    "\n",
    "Testset=[[], [], [], [], [], [], [], [], [], []]\n",
    "Testset\n",
    "\n",
    "courseraLib.printProgressBar(i, l, prefix = 'TestSet'+\":\", suffix = 'Complete')\n",
    "for line in testing_set:\n",
    "    p=random.randint(1,1000)\n",
    "    if (p)<=sample_rate:\n",
    "#         print('\\n',p)\n",
    "        EoSentence=\"[.,;!?]+\"\n",
    "        line_test=re.sub(EoSentence,\"\\n\",line)\n",
    "        line_test=line_test.split(\"\\n\")\n",
    "        line_in=line_test[0]\n",
    "        if len(line_in)<5:\n",
    "            continue\n",
    "        if len(line_in)>15:\n",
    "            line_in=line_in[random.randint(5,10)]\n",
    "        Testset[(p-1)].append(line_test[0])\n",
    "    i+=1\n",
    "    courseraLib.printProgressBar(i, l, prefix = 'TestSet'+\":\", suffix = 'Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nGramDict=\\\n",
    "json.load(open\\\n",
    "('/home/yewenhe0904/Developing/ds-capstone-project/ignoredFiles/Sample-Dict/mixed-nGramDict_10_1.json'))\n",
    "\n",
    "def cleanInputPredict(test_input):\n",
    "    cleanedInput=[]\n",
    "    test_tokens=test_input.strip().lower().split()\n",
    "    test_input=re.sub('\\n+',\" \",test_input)\n",
    "    for item in test_tokens:\n",
    "        item = item.strip(string.punctuation)\n",
    "        item = re.sub(r\"^.*\\d+.*$\",\"<quantity>\",item)\n",
    "        cleanedInput.append(item)\n",
    "    return cleanedInput\n",
    "\n",
    "def predictCore(input_tokens,output_list,out_len=5):  \n",
    "    input_tokens_o=input_tokens # backup original string\n",
    "    if len(input_tokens)<1:\n",
    "        output_list+=(nGramDict['_r'])\n",
    "    else:\n",
    "        # replace by word stem\n",
    "        if '_word2stem' in nGramDict:\n",
    "            if input_tokens[0] in nGramDict['_word2stem']['_stem']:\n",
    "                input_tokens[0]=nGramDict['_word2stem']['_stem'][input_tokens[0]]\n",
    "                \n",
    "        # word to wid\n",
    "#         print(input_tokens)\n",
    "        input_idtokens=[]\n",
    "        for w in input_tokens:\n",
    "            w.strip()\n",
    "            if w in nGramDict['_word2id']['_word']:\n",
    "                input_idtokens.append(nGramDict['_word2id']['_word'][w])\n",
    "            else:\n",
    "                input_idtokens.append('NA')\n",
    "        \n",
    "        input_tokens=input_idtokens\n",
    "#         print(input_tokens)\n",
    "        # probe if in ngram record\n",
    "        nGram_flag=True\n",
    "        i=0\n",
    "        p_Dict=nGramDict['_n']\n",
    "        while nGram_flag:\n",
    "#             print(i)\n",
    "            if i==len(input_tokens):\n",
    "                break\n",
    "            if (input_tokens[i] in p_Dict):\n",
    "                r_wids=p_Dict[input_tokens[i]]['_r']\n",
    "                if ('_n' in p_Dict[input_tokens[i]]):\n",
    "                    p_Dict=p_Dict[input_tokens[i]]['_n']\n",
    "                    i+=1\n",
    "                else:\n",
    "                    if i<len(input_tokens)-1:\n",
    "                        nGram_flag=False\n",
    "                    break\n",
    "            else:\n",
    "                nGram_flag=False\n",
    "                break\n",
    "        \n",
    "        # if true\n",
    "        if nGram_flag:\n",
    "            output_list+=r_wids\n",
    "#             print(output_list)\n",
    "#             print('find')\n",
    "            if len(output_list)<out_len:\n",
    "                del input_tokens_o[0]\n",
    "                predictCore(input_tokens_o,output_list,out_len=out_len)\n",
    "        # else false\n",
    "        else:\n",
    "            del input_tokens_o[0]\n",
    "            predictCore(input_tokens_o,output_list,out_len=out_len)\n",
    "\n",
    "def predictNgram(test_input,out_len):\n",
    "    #clean input string\n",
    "    input_tokens=cleanInputPredict(test_input)\n",
    "    if len(input_tokens)>=nGramDict['_model']:\n",
    "        input_tokens=input_tokens[(-nGramDict['_model']+1):]\n",
    "#         print(input_tokens)\n",
    "    output_list=[]\n",
    "    output_wlist=[]\n",
    "    output=[]\n",
    "    predictCore(input_tokens,output_list,out_len)\n",
    "    for wid in output_list:\n",
    "        output_wlist.append(nGramDict['_id2word']['_id'][wid])\n",
    "    eosflag=True\n",
    "#     print(output_wlist)\n",
    "    for word in output_wlist:\n",
    "        if word=='<eos>':\n",
    "            if eosflag:\n",
    "                output.append(',')\n",
    "                output.append('.')\n",
    "            eosflag=False\n",
    "        elif word==\"<quantity>\":\n",
    "            continue\n",
    "        else:\n",
    "            output.append(word)\n",
    "        #dedupe\n",
    "        output_dp=[output[0]]\n",
    "        if len(output)>1:\n",
    "            for i in range(1,len(output)):\n",
    "                if output[i] not in output[:i]:\n",
    "                    output_dp.append(output[i])\n",
    "        if len(output_dp)>out_len:\n",
    "            output_dp=output_dp[0:out_len]\n",
    "    return output_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', 'are', 'taj', 'the', 'all', 'to', 'and', 'a']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_input=\"donald trump\"\n",
    "predictNgram(t_input,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 :\n",
      "length of current test: 2824\n",
      "714 / 2824 25.28%\n",
      "Test 2 :\n",
      "length of current test: 2753\n",
      "677 / 2753 24.59%\n",
      "Test 3 :\n",
      "length of current test: 2783\n",
      "726 / 2783 26.09%\n",
      "Test 4 :\n",
      "length of current test: 2771\n",
      "721 / 2771 26.02%\n",
      "Test 5 :\n",
      "length of current test: 2604\n",
      "659 / 2604 25.31%\n",
      "Test 6 :\n",
      "length of current test: 2745\n",
      "687 / 2745 25.03%\n",
      "Test 7 :\n",
      "length of current test: 2737\n",
      "677 / 2737 24.74%\n",
      "Test 8 :\n",
      "length of current test: 2784\n",
      "673 / 2784 24.17%\n",
      "Test 9 :\n",
      "length of current test: 2698\n",
      "732 / 2698 27.13%\n",
      "Test 10 :\n",
      "length of current test: 2759\n",
      "736 / 2759 26.68%\n",
      "TOTAL AVERAGE:  7002 / 27458 25.5%\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "total_t=0\n",
    "right_t=0\n",
    "for t in Testset:\n",
    "    i+=1\n",
    "    print('Test',i,\":\")\n",
    "    total=0\n",
    "    right=0\n",
    "    print('length of current test:',len(t))\n",
    "    for s in t:\n",
    "        stest=s.strip().lower().split()\n",
    "        key=stest[-1]\n",
    "        del stest[-1]\n",
    "        q_input=' '.join(stest)\n",
    "        if key in predictNgram(q_input,20):\n",
    "            right+=1\n",
    "        total+=1\n",
    "    print(right,'/',total,str(round(right/total*100,2))+'%')\n",
    "    total_t+=total\n",
    "    right_t+=right\n",
    "print('TOTAL AVERAGE: ',right_t,'/',total_t,str(round(right_t/total_t*100,2))+'%')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
