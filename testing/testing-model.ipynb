{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json,os,sys,logging,pprint,re,string,courseraLib,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestSet: |█████████████████████████████-| 99.9% Complete\r"
     ]
    }
   ],
   "source": [
    "sample_rate=10 #1/1000\n",
    "path='/home/yewenhe0904/Developing/ds-capstone-project/testing-data/mixed-testing.txt'\n",
    "testing_set=open(path)\n",
    "\n",
    "\n",
    "# Initial call to print 0% progress\n",
    "i = 0\n",
    "l = len(list(open(path)))\n",
    "l\n",
    "\n",
    "Testset=[[], [], [], [], [], [], [], [], [], []]\n",
    "Testset\n",
    "\n",
    "courseraLib.printProgressBar(i, l, prefix = 'TestSet'+\":\", suffix = 'Complete')\n",
    "for line in testing_set:\n",
    "    p=random.randint(1,1000)\n",
    "    if (p)<=sample_rate:\n",
    "#         print('\\n',p)\n",
    "        EoSentence=\"[.,;!?]+\"\n",
    "        line_test=re.sub(EoSentence,\"\\n\",line)\n",
    "        line_test=line_test.split(\"\\n\")\n",
    "        line_in=line_test[0]\n",
    "        if len(line_in)<5:\n",
    "            continue\n",
    "        if len(line_in)>15:\n",
    "            line_in=line_in[random.randint(5,10)]\n",
    "        Testset[(p-1)].append(line_test[0])\n",
    "    i+=1\n",
    "    courseraLib.printProgressBar(i, l, prefix = 'TestSet'+\":\", suffix = 'Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nGramDict=\\\n",
    "json.load(open('/home/yewenhe0904/Developing/ds-capstone-project/ignoredFiles/Sample-Dict/mixed-nGramDict_50_5.json'))\n",
    "\n",
    "def cleanInputPredict(test_input):\n",
    "    cleanedInput=[]\n",
    "    test_tokens=test_input.strip().lower().split()\n",
    "    test_input=re.sub('\\n+',\" \",test_input)\n",
    "    for item in test_tokens:\n",
    "        item = item.strip(string.punctuation)\n",
    "        item = re.sub(r\"^.*\\d+.*$\",\"<Quantity>\",item)\n",
    "        cleanedInput.append(item)\n",
    "    return cleanedInput\n",
    "\n",
    "def predictCore(input_tokens,output_list,out_len=5):\n",
    "#     print (input_tokens)\n",
    "    if len(input_tokens)<1:\n",
    "        output_list+=(nGramDict['_r'])\n",
    "    else:\n",
    "        # probe if in ngram record\n",
    "        nGram_flag=True\n",
    "        i=0\n",
    "        p_Dict=nGramDict['_n']\n",
    "        while nGram_flag:\n",
    "#             print(i)\n",
    "            if i==len(input_tokens):\n",
    "                break\n",
    "            if (input_tokens[i] in p_Dict):\n",
    "                r_wids=p_Dict[input_tokens[i]]['_r']\n",
    "                if ('_n' in p_Dict[input_tokens[i]]):\n",
    "                    p_Dict=p_Dict[input_tokens[i]]['_n']\n",
    "                    i+=1\n",
    "                else:\n",
    "                    if i<len(input_tokens)-1:\n",
    "                        nGram_flag=False\n",
    "                    break\n",
    "            else:\n",
    "                nGram_flag=False\n",
    "                break\n",
    "        # if true\n",
    "        if nGram_flag:\n",
    "            output_list+=r_wids\n",
    "            if len(output_list)<out_len:\n",
    "                del input_tokens[0]\n",
    "                predictCore(input_tokens,output_list,out_len=out_len)\n",
    "        # else false\n",
    "        else:\n",
    "            del input_tokens[0]\n",
    "            predictCore(input_tokens,output_list,out_len=out_len)\n",
    "\n",
    "def predictNgram(test_input,out_len):\n",
    "    #clean input string\n",
    "    input_tokens=cleanInputPredict(test_input)\n",
    "    if len(input_tokens)>nGramDict['_model']:\n",
    "        input_tokens=input_tokens[-nGramDict['_model']:]\n",
    "    output_list=[]\n",
    "    output_wlist=[]\n",
    "    output=[]\n",
    "    input_idtokens=[]\n",
    "    for w in input_tokens:\n",
    "        w.strip()\n",
    "        if w in nGramDict['_word2id']['_word']:\n",
    "            input_idtokens.append(nGramDict['_word2id']['_word'][w])\n",
    "        else:\n",
    "            input_idtokens.append('NA')\n",
    "    predictCore(input_idtokens,output_list,out_len)\n",
    "    for wid in output_list:\n",
    "        output_wlist.append(nGramDict['_id2word']['_id'][wid])\n",
    "    eosflag=True\n",
    "#     print(output_wlist)\n",
    "    for word in output_wlist:\n",
    "        if word=='<EOS>':\n",
    "            if eosflag:\n",
    "                output.append(',')\n",
    "                output.append('.')\n",
    "            eosflag=False\n",
    "        elif word==\"<Quantity>\":\n",
    "            continue\n",
    "        else:\n",
    "            output.append(word)\n",
    "        #dedupe\n",
    "        output_dp=[output[0]]\n",
    "        if len(output)>1:\n",
    "            for i in range(1,len(output)):\n",
    "                if output[i] not in output[:i]:\n",
    "                    output_dp.append(output[i])\n",
    "        if len(output_dp)>out_len:\n",
    "            output_dp=output_dp[0:out_len]\n",
    "    return output_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 :\n",
      "length of current test: 153\n",
      "47 / 153 30.72%\n",
      "Test 2 :\n",
      "length of current test: 162\n",
      "48 / 162 29.63%\n",
      "Test 3 :\n",
      "length of current test: 162\n",
      "47 / 162 29.01%\n",
      "Test 4 :\n",
      "length of current test: 151\n",
      "41 / 151 27.15%\n",
      "Test 5 :\n",
      "length of current test: 182\n",
      "46 / 182 25.27%\n",
      "Test 6 :\n",
      "length of current test: 156\n",
      "36 / 156 23.08%\n",
      "Test 7 :\n",
      "length of current test: 163\n",
      "42 / 163 25.77%\n",
      "Test 8 :\n",
      "length of current test: 177\n",
      "50 / 177 28.25%\n",
      "Test 9 :\n",
      "length of current test: 158\n",
      "40 / 158 25.32%\n",
      "Test 10 :\n",
      "length of current test: 160\n",
      "45 / 160 28.12%\n",
      "TOTAL AVERAGE:  442 / 1624 27.22%\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "total_t=0\n",
    "right_t=0\n",
    "for t in Testset:\n",
    "    i+=1\n",
    "    print('Test',i,\":\")\n",
    "    total=0\n",
    "    right=0\n",
    "    print('length of current test:',len(t))\n",
    "    for s in t:\n",
    "        stest=s.strip().lower().split()\n",
    "        key=stest[-1]\n",
    "        del stest[-1]\n",
    "        q_input=' '.join(stest)\n",
    "        if key in predictNgram(q_input,10):\n",
    "            right+=1\n",
    "        total+=1\n",
    "    print(right,'/',total,str(round(right/total*100,2))+'%')\n",
    "    total_t+=total\n",
    "    right_t+=right\n",
    "print('TOTAL AVERAGE: ',right_t,'/',total_t,str(round(right_t/total_t*100,2))+'%')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
